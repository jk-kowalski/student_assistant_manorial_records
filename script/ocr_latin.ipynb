{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5a6be8b",
   "metadata": {},
   "source": [
    "This is a markdown cell. It describes the purpose of this notebook and its code.\n",
    "\n",
    "This notebook will transform a PDF scan of a Latin record into Word doc (Latin), and then translate it to English including its numerals. Final output is a Word doc (English).\n",
    "\n",
    "Last updated by Kuba Kowalski on 11/11/2025, 23:00."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21f2eb3",
   "metadata": {},
   "source": [
    "## Applying OCR to raw scans\n",
    "\n",
    "Embedding selectable text into PDF to make conversion to Word possible. Note, this is needed because while the original scans appear to have selectable text, it's actually full of errors and cannot be trusted. \n",
    "\n",
    "OCR is the standard used for other Winchester Pipe Rolls. No need to reinvent the wheel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9e51fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ocrmypdf in c:\\users\\kubak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (16.11.1)\n",
      "Requirement already satisfied: pdfplumber in c:\\users\\kubak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.11.7)\n",
      "Requirement already satisfied: python-docx in c:\\users\\kubak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: deprecation>=2.1.0 in c:\\users\\kubak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ocrmypdf) (2.1.0)\n",
      "Requirement already satisfied: img2pdf>=0.5 in c:\\users\\kubak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ocrmypdf) (0.6.3)\n",
      "Requirement already satisfied: packaging>=20 in c:\\users\\kubak\\appdata\\roaming\\python\\python311\\site-packages (from ocrmypdf) (25.0)\n",
      "Requirement already satisfied: pdfminer-six>=20220319 in c:\\users\\kubak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ocrmypdf) (20250506)\n",
      "Requirement already satisfied: pi-heif in c:\\users\\kubak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ocrmypdf) (1.1.1)\n",
      "Requirement already satisfied: pikepdf!=9.8.0,>=8.10.1 in c:\\users\\kubak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ocrmypdf) (10.0.2)\n",
      "Requirement already satisfied: pillow>=10.0.1 in c:\\users\\kubak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ocrmypdf) (11.3.0)\n",
      "Requirement already satisfied: pluggy>=1 in c:\\users\\kubak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ocrmypdf) (1.6.0)\n",
      "Requirement already satisfied: rich>=13 in c:\\users\\kubak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ocrmypdf) (14.2.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\kubak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pdfplumber) (4.30.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\kubak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pdfminer-six>=20220319->ocrmypdf) (3.4.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\kubak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pdfminer-six>=20220319->ocrmypdf) (46.0.3)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\kubak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-docx) (6.0.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\kubak\\appdata\\roaming\\python\\python311\\site-packages (from python-docx) (4.14.1)\n",
      "Requirement already satisfied: Deprecated in c:\\users\\kubak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pikepdf!=9.8.0,>=8.10.1->ocrmypdf) (1.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\kubak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=13->ocrmypdf) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kubak\\appdata\\roaming\\python\\python311\\site-packages (from rich>=13->ocrmypdf) (2.19.2)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\kubak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cryptography>=36.0.0->pdfminer-six>=20220319->ocrmypdf) (2.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\kubak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13->ocrmypdf) (0.1.2)\n",
      "Requirement already satisfied: wrapt<3,>=1.10 in c:\\users\\kubak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Deprecated->pikepdf!=9.8.0,>=8.10.1->ocrmypdf) (2.0.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\kubak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer-six>=20220319->ocrmypdf) (2.23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Sudo is disabled on this machine. To enable it, go to the \u001b]8;;ms-settings:developers\u001b\\Developer Settings page\u001b]8;;\u001b\\ in the Settings app\n"
     ]
    }
   ],
   "source": [
    "# Install for convenience\n",
    "!pip install ocrmypdf pdfplumber python-docx\n",
    "\n",
    "!sudo apt-get install -y tesseract-ocr tesseract-ocr-lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5657cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import pdfplumber\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1573f4",
   "metadata": {},
   "source": [
    "### IMPORTANT BEFORE RUNNING\n",
    "\n",
    "The cell below will fail is tesseract and ghostscript are not correctly installed or visible on your Windows install. To fix it, follow steps listed below (For Linux solution, ask ChatGPT):\n",
    "1. Open Windows PowerShell as admin\n",
    "2. Run \"Get-ExecutionPolicy\". If returns \"restricted\", run \"Set-ExecutionPolicy Bypass -Scope Process -Force\". Otherwise, continue to step 3\n",
    "3. Install Chocolatey (Run as single line): Set-ExecutionPolicy Bypass -Scope Process -Force; `\n",
    "[System.Net.ServicePointManager]::SecurityProtocol = `\n",
    "[System.Net.ServicePointManager]::SecurityProtocol -bor 3072; `\n",
    "iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))\n",
    "4. Verify install: \"choco --version\"\n",
    "5. Open Command Prompt as admin\n",
    "6. Install tesseract: \"choco install tesseract\"\n",
    "7. Input \"Y\" in Command Prompt\n",
    "8. Install ghostscript: \"choco install ghostscript\"\n",
    "9. Input \"Y\" in Command Prompt\n",
    "10. Download Latin package for tesseract from here: [lat.traineddata](https://github.com/tesseract-ocr/tessdata_best/blob/main/lat.traineddata). Save to \"C:\\Program Files\\Tesseract-OCR\\tessdata\\lat.traineddata\" or any other location where tesseract is installed. To check install location, run \"tesseract --print-parameters | findstr /C:\"tessdata\" in Command Prompt\n",
    "\n",
    "Note, Chocolatey is a convenient installer. Ghostscript is default choice for OCR. There is a manual way of installing tesseract & ghostscript without Choco, but I won't explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9466093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR processing input: Cuxham_1276.pdf -> Cuxham_1276_ocr.pdf\n",
      "Task succesful: Cuxham_1276.pdf\n",
      "OCR processing input: Cuxham_1288.pdf -> Cuxham_1288_ocr.pdf\n",
      "Task succesful: Cuxham_1288.pdf\n"
     ]
    }
   ],
   "source": [
    "# Runtime: 45 sec per input file. \n",
    "\n",
    "# Example bash !ocrmypdf --force-ocr -l lat+eng Cuxham_1288.pdf Cuxham_1288_ocr.pdf\n",
    "    ## --force-ocr is needed to overwrite original text layer\n",
    "    ## -l lat+eng is needed to handle mix of English & Latin, suggested by GPT-5\n",
    "    ## Cuxham_1288.pdf is the input\n",
    "    ## Cuxham_1288_ocr.pdf is the output\n",
    "\n",
    "# Paths\n",
    "\n",
    "## Input\n",
    "input_dir = Path(r\"C:\\Users\\kubak\\OneDrive - Wageningen University & Research\\WUR\\2024-2025\\research_assistant_ox\\workfolder\\input\\Latin\\Cuxham\")\n",
    "\n",
    "## Output: where to save OCR’d files (can be same as input)\n",
    "output_dir = Path(r\"C:\\Users\\kubak\\OneDrive - Wageningen University & Research\\WUR\\2024-2025\\research_assistant_ox\\workfolder\\output\\Latin\\Cuxham\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# The bash command above is rebuilt for Python use below\n",
    "    ## Most convenient way for looping through multiple input PDFs (Latin)\n",
    "for pdf_file in input_dir.glob(\"*.pdf\"):\n",
    "    output_pdf = output_dir / f\"{pdf_file.stem}_ocr.pdf\"\n",
    "    \n",
    "    print(f\"OCR processing input: {pdf_file.name} -> {output_pdf.name}\")\n",
    "\n",
    "    cmd = [\n",
    "        \"ocrmypdf\",\n",
    "        \"--force-ocr\",\n",
    "        \"-l\", \"lat+eng\",\n",
    "        str(pdf_file),\n",
    "        str(output_pdf)\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        subprocess.run(cmd, check=True)\n",
    "        print(f\"Task succesful: {pdf_file.name}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Task failed (fix your directories or follow 10 steps above): {pdf_file.name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15de489b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Cuxham_1276_ocr.pdf → Cuxham_1276.docx\n",
      "Saved: C:\\Users\\kubak\\OneDrive - Wageningen University & Research\\WUR\\2024-2025\\research_assistant_ox\\workfolder\\output\\Latin\\Cuxham\\word\\Cuxham_1276.docx\n",
      "Converting Cuxham_1288_ocr.pdf → Cuxham_1288.docx\n",
      "Saved: C:\\Users\\kubak\\OneDrive - Wageningen University & Research\\WUR\\2024-2025\\research_assistant_ox\\workfolder\\output\\Latin\\Cuxham\\word\\Cuxham_1288.docx\n"
     ]
    }
   ],
   "source": [
    "# Path\n",
    "word_dir = output_dir / \"word\"\n",
    "word_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Function for conversion of OCR PDF to Word\n",
    "def pdf_to_docx(pdf_path: Path, docx_path: Path):\n",
    "    doc = Document()\n",
    "    doc.add_heading(pdf_path.stem, level=1)\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_no, page in enumerate(pdf.pages, start=1):\n",
    "            text = page.extract_text() or \"\"\n",
    "            text = text.strip()\n",
    "            if not text:\n",
    "                continue\n",
    "\n",
    "            # Add a page marker\n",
    "            doc.add_paragraph(f\"[Page {page_no}]\")\n",
    "\n",
    "            # Split into paragraphs on newline\n",
    "            for line in text.split(\"\\n\"):\n",
    "                if line.strip():\n",
    "                    doc.add_paragraph(line.strip())\n",
    "\n",
    "            # Add a blank line between pages\n",
    "            doc.add_paragraph(\"\")\n",
    "\n",
    "    doc.save(docx_path)\n",
    "    print(f\"Saved: {docx_path}\")\n",
    "\n",
    "# Conversion of OCR PDFs to Word\n",
    "for pdf_file in output_dir.glob(\"*_ocr.pdf\"):\n",
    "    docx_name = pdf_file.stem.replace(\"_ocr\", \"\") + \".docx\"\n",
    "    docx_path = word_dir / docx_name\n",
    "    print(f\"Converting {pdf_file.name} → {docx_name}\")\n",
    "    pdf_to_docx(pdf_file, docx_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b95601",
   "metadata": {},
   "source": [
    "## Latin Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a75a90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install for convenience\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145e4e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7848cc85",
   "metadata": {},
   "source": [
    "Example line of code below if you want you set the ChatGPT key immediately in the Jupyter Notebook. Not doing this myself since the GitHub repo is public (for now). \n",
    "\n",
    "If anyone reading this ever thinks to do it, better not. \n",
    "You will be charged money for anyone using your key which would be there for literally everyone in the world with Internet access to see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb0b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't do this\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-your-real-key-here\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa13beb",
   "metadata": {},
   "source": [
    "You can find your key through this link by logging in: https://platform.openai.com/api-keys\n",
    "\n",
    "Instructions for setting the OpenAI API key:\n",
    "1. Open PowerShell\n",
    "2. Run with your key: setx OPENAI_API_KEY \"sk-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1199da3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe alternative for setting the API key, follow instructions in Markdown cell above\n",
    "client = OpenAI() # This takes the key from your env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f49c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_dir = Path(r\"C:\\Users\\kubak\\OneDrive - Wageningen University & Research\\WUR\\2024-2025\\research_assistant_ox\\workfolder\\output\\Latin\\Cuxham\")\n",
    "\n",
    "def chunk_pages(pages, max_chars=6000):\n",
    "    chunks = []\n",
    "    current = []\n",
    "    current_len = 0\n",
    "\n",
    "    for page_no, text in enumerate(pages, start=1):\n",
    "        header = f\"[Page {page_no}]\\n\"\n",
    "        block = header + text + \"\\n\\n\"\n",
    "        if current_len + len(block) > max_chars and current:\n",
    "            chunks.append(\"\".join(current))\n",
    "            current = [block]\n",
    "            current_len = len(block)\n",
    "        else:\n",
    "            current.append(block)\n",
    "            current_len += len(block)\n",
    "\n",
    "    if current:\n",
    "        chunks.append(\"\".join(current))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_pages(pages)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddf11c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a professional translator of medieval Latin manorial accounts into modern English.\n",
    "\n",
    "Tasks, in order:\n",
    "1. Silently fix obvious OCR errors in the Latin (split words, wrong letters, stray punctuation), \n",
    "   but do NOT modernize spelling unnecessarily.\n",
    "2. Translate the corrected Latin into clear, modern English.\n",
    "3. Preserve all ROMAN NUMERALS exactly as written (e.g. xiiij, xxvij, MCCXL).\n",
    "4. Preserve any page markers like [Page 3].\n",
    "5. If some lines are already in English (editorial headings, notes), keep them as they are.\n",
    "\"\"\"\n",
    "\n",
    "def translate_chunk(text_block, target_language=\"English\"):\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1-mini\",  # or e.g. \"gpt-5\" if costs aren't an issue\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": text_block},\n",
    "        ],\n",
    "    )\n",
    "    return response.output_text\n",
    "\n",
    "def translate_pdf_to_blocks(pdf_path):\n",
    "    pages = extract_pages(pdf_path)\n",
    "    chunks = chunk_pages(pages)\n",
    "    \n",
    "    translated_chunks = []\n",
    "    for i, chunk in enumerate(chunks, start=1):\n",
    "        print(f\"Translating chunk {i}/{len(chunks)} for {pdf_path.name}...\")\n",
    "        translated = translate_chunk(chunk)\n",
    "        translated_chunks.append(translated)\n",
    "    return translated_chunks\n",
    "\n",
    "translated_chunks = translate_pdf_to_blocks(pdf_path)\n",
    "len(translated_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f1e655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_ocr_pdf(pdf_path, out_dir):\n",
    "    translated_chunks = translate_pdf_to_blocks(pdf_path)\n",
    "    out_name = pdf_path.stem.replace(\"_ocr\", \"\") + \"_translation.docx\"\n",
    "    out_path = out_dir / out_name\n",
    "    save_translation_docx(translated_chunks, out_path, title=pdf_path.stem)\n",
    "    print(f\"Saved translation to: {out_path}\")\n",
    "    return out_path\n",
    "\n",
    "for pdf_file in ocr_dir.glob(\"*_ocr.pdf\"):\n",
    "    translate_ocr_pdf(pdf_file, ocr_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
